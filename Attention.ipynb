{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9536b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4473469-686d-4abf-8041-d5ea6cda75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, model_dim, dropout=0.1):\n",
    "        # super() delegates the function call to the parent class, nn.Module\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.qkv_weights = nn.ModuleList()\n",
    "        \n",
    "        q_weight = nn.Linear(emb_dim, model_dim)\n",
    "        k_weight = nn.Linear(emb_dim, model_dim)\n",
    "        v_weight = nn.Linear(emb_dim, model_dim)\n",
    "        \n",
    "        self.qkv_weights.append(nn.ModuleList([q_weight, k_weight, v_weight]))\n",
    "        \n",
    "        self.out_proj = nn.Linear(model_dim, emb_dim)\n",
    "        \n",
    "        #dropout layer\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def attention_op(self, q, k, v):\n",
    "        # Dot-product bewteen\n",
    "        q_k = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "        argument = q_k / math.sqrt(model_dim)\n",
    "        \n",
    "        #softmax part\n",
    "        S = F.softmax(argument, dim=-1)\n",
    "        \n",
    "        result = torch.matmul(S, v)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def forward(self, query, key, value):\n",
    "        output = [self.attention_op(Q(query), K(key), V(value)) for Q, K, V in self.qkv_weights]\n",
    "        output = torch.cat(output, dim=-1) #last dimension\n",
    "        \n",
    "        # result = nn.Linear(output) # this already being done by self.out_proj\n",
    "        \n",
    "        output = self.out_proj(output)\n",
    "        \n",
    "        return self.drop(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61991326-81e9-4d06-a32f-f5aa1ccf5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4963, 0.7682, 0.0885,  ..., 0.6673, 0.3561, 0.8091],\n",
       "         [0.3613, 0.3136, 0.6259,  ..., 0.1876, 0.2099, 0.7210],\n",
       "         [0.4650, 0.0278, 0.2117,  ..., 0.5025, 0.4458, 0.2083],\n",
       "         ...,\n",
       "         [0.1100, 0.0771, 0.6113,  ..., 0.7174, 0.6193, 0.0636],\n",
       "         [0.8637, 0.4471, 0.2902,  ..., 0.9446, 0.1363, 0.9336],\n",
       "         [0.9479, 0.9039, 0.5435,  ..., 0.6666, 0.7545, 0.5523]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "emb_dim = 512\n",
    "model_dim = 512\n",
    "seq_len = 10\n",
    "\n",
    "test = torch.rand((1, seq_len, emb_dim))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30fd3cb9-f965-42be-a524-0695d7b6765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single = SingleAttention(emb_dim, model_dim)\n",
    "\n",
    "expected = nn.MultiheadAttention(emb_dim, num_heads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cba98d1-8ead-4f50-be56-eacc270de865",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mine = single(test, test, test)\n",
    "\n",
    "out_torch = expected(test, test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca17cf2b-b1cf-48cc-9e80-7729ee5723cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine:  torch.Size([1, 10, 512])\n",
      "torch:  torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"mine: \", out_mine.shape)\n",
    "print(\"torch: \", out_torch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb3a9f-f5ea-439e-b51c-5d366d0bf87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
